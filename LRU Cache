# LRU Cache 

##  Problem Statement
Design and implement a *Least Recently Used (LRU) cache*.  
It should support the following operations in *O(1) time*:
- get(key): return the value if the key exists, otherwise -1.
- put(key, value): insert or update the key with given value.  
  If the cache exceeds its capacity, evict the *least recently used* key.

 Approach
We use a combination of:
1. **HashMap (dict)** → for O(1) access to nodes.  
   Stores key -> Node.
2. *Doubly Linked List* → for tracking usage order.  
   - Most recently used (MRU) items are near the tail.  
   - Least recently used (LRU) item is right after the head.

Why Doubly Linked List?
- We can *insert* and *remove* nodes in O(1) time by updating pointers.
- Head (oldest) and Tail (latest) are *dummy nodes* to simplify insert/remove operations (no null checks).

---

## ⚙ Code Explanation

### Node structure
Each node stores:
- key
- value
- prev pointer
- next pointer

### LRUCache methods
- **get(key)**
  - If key exists: move node to MRU position (near tail) and return its value.
  - Else: return -1.

- **put(key, value)**
  - If key exists: remove old node.
  - Insert new node as MRU.
  - If capacity exceeded: remove LRU node (oldest.next) and delete from hashmap.

- **remove(node)**
  - Disconnects node from linked list by linking its neighbors together.

- **insert(node)**
  - Always inserts node right before the latest sentinel (MRU position).


##  Complexity Analysis
- *Time Complexity*:  
  - get() → O(1)  
  - put() → O(1)  

- *Space Complexity*:  
  - O(capacity) for storing up to capacity nodes in hashmap + linked list.

## Example Dry Run
```python
cache = LRUCache(2)

cache.put(1, 10)   # cache = {1=10}
cache.put(2, 20)   # cache = {1=10, 2=20}
print(cache.get(1))  # returns 10, makes 1 most recent
cache.put(3, 30)   # evicts key 2, cache = {1=10, 3=30}
print(cache.get(2))  # returns -1 (not found)
print(cache.get(3))  # returns 30
